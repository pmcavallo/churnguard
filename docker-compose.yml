version: '3.8'

services:
  # ChurnGuard Prediction API
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./artifacts:/app/artifacts
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow

  # MLflow Tracking Server
  mlflow:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    working_dir: /mlruns
    command: >
      bash -c "pip install mlflow --quiet && 
               mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri /mlruns"
